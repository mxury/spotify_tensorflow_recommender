{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist          object\n",
      "track_id        object\n",
      "track           object\n",
      "owner           object\n",
      "artist&track    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "              artist                track_id                     track  \\\n0         Romanthony  1iwZVgKv3FKc0dqhnSG9uW            Get It 2 Getta   \n1  Glenn Underground  2JFeAyJLMPPsBkklQEet6t                   H-Dance   \n2          DJ BORING  3ilkEyg6OCtd9qCnOJkPzU                    Winona   \n3          Josh Wink  7sBAYj9DLDYz8lFMV89cF6  Meditation Will Manifest   \n4            Lazarus  5Nlm87K2iVmNh2hBnIxmxf                 Harbinger   \n\n                       owner                        artist&track  \n0  kv718oiku8q612q0zi4iaovzb           Romanthony/Get It 2 Getta  \n1  kv718oiku8q612q0zi4iaovzb           Glenn Underground/H-Dance  \n2  kv718oiku8q612q0zi4iaovzb                    DJ BORING/Winona  \n3  kv718oiku8q612q0zi4iaovzb  Josh Wink/Meditation Will Manifest  \n4  kv718oiku8q612q0zi4iaovzb                   Lazarus/Harbinger  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>track_id</th>\n      <th>track</th>\n      <th>owner</th>\n      <th>artist&amp;track</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Romanthony</td>\n      <td>1iwZVgKv3FKc0dqhnSG9uW</td>\n      <td>Get It 2 Getta</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>Romanthony/Get It 2 Getta</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Glenn Underground</td>\n      <td>2JFeAyJLMPPsBkklQEet6t</td>\n      <td>H-Dance</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>Glenn Underground/H-Dance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DJ BORING</td>\n      <td>3ilkEyg6OCtd9qCnOJkPzU</td>\n      <td>Winona</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>DJ BORING/Winona</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Josh Wink</td>\n      <td>7sBAYj9DLDYz8lFMV89cF6</td>\n      <td>Meditation Will Manifest</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>Josh Wink/Meditation Will Manifest</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lazarus</td>\n      <td>5Nlm87K2iVmNh2hBnIxmxf</td>\n      <td>Harbinger</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>Lazarus/Harbinger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database is small enough to be read into memory hence we will use pandas and then cast it into a tf.data object\n",
    "df = pd.read_csv('./data/database_model_ready.csv')\n",
    "df = df.astype(str)\n",
    "all_tracks = df['artist&track'].unique()\n",
    "pprint(df.dtypes)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Romanthony/Get It 2 Getta', 'Glenn Underground/H-Dance',\n       'DJ BORING/Winona', ..., 'Joni Mitchell/Edith and the Kingpin',\n       \"Joni Mitchell/Don't Interrupt the Sorrow\",\n       'Joni Mitchell/The Hissing of Summer Lawns'], dtype=object)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tracks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "user_data = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "tracks = tf.data.Dataset.from_tensor_slices({'artist&track' : all_tracks})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist': b'Romanthony', 'track_id': b'1iwZVgKv3FKc0dqhnSG9uW', 'track': b'Get It 2 Getta', 'owner': b'kv718oiku8q612q0zi4iaovzb', 'artist&track': b'Romanthony/Get It 2 Getta'}\n"
     ]
    }
   ],
   "source": [
    "for row in user_data.take(1).as_numpy_iterator():\n",
    "    print(row)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist&track': b'Romanthony/Get It 2 Getta'}\n"
     ]
    }
   ],
   "source": [
    "for row in tracks.take(1).as_numpy_iterator():\n",
    "    print(row)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "user_songs = user_data.map(lambda x: {\n",
    "    'user': x['owner'],\n",
    "    'artist&track': x['artist&track'],\n",
    "})\n",
    "\n",
    "tracks = tracks.map(lambda x: x['artist&track'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "array([b' Sentinel/Toulepleu', b'!!!/Fine Fine Fine', b'!!!/Myth Takes',\n       b'!!!/NRGQ',\n       b'#1 Movie Favorites/The Winner Is (From Little Miss Sunshine)',\n       b'#TocoParaVos/Se Pic\\xc3\\xb3', b'$MOKE OG/$MOKE OG',\n       b'$NOT/\"Life\"', b'$NOT/5AM', b'$NOT/BENZO'], dtype=object)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "buffersize = df.shape[0]\n",
    "shuffled = user_songs.shuffle(buffersize, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(0.8*buffersize))\n",
    "test = shuffled.skip(int(0.8*buffersize)).take(int(0.2*buffersize))\n",
    "\n",
    "track_names = tracks.batch(1_000)\n",
    "user_ids = user_songs.batch(1_000_000).map(lambda x: x[\"user\"])\n",
    "\n",
    "unique_track_names = np.unique(np.concatenate(list(track_names)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_track_names[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieval model\n",
    "\n",
    "Following the tutorial from [Tensforlow](https://www.tensorflow.org/recommenders/examples/basic_retrieval)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query and candidate towers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "# stringlook up encodes the user id's as contingous integers and then uses an embedding\n",
    "# similar process for the\n",
    "user_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids,\n",
    "            mask_token=None,\n",
    "        ),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
    "    ]\n",
    ")\n",
    "\n",
    "track_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_track_names,\n",
    "            mask_token=None,\n",
    "        ),\n",
    "        tf.keras.layers.Embedding(len(unique_track_names) + 1, embedding_dimension)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=tracks.batch(128).map(track_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Full retrieval model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "class TrackRetrievalModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, usr_model, track_model):\n",
    "        super().__init__()\n",
    "        self.track_model: tf.keras.Model = track_model\n",
    "        self.user_model: tf.keras.Model = usr_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user\"])\n",
    "        # And pick out the track features and pass them into the track model,\n",
    "        # getting embeddings back.\n",
    "        positive_track_embeddings = self.track_model(features[\"artist&track\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_track_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting and evaluating the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 11:30:08.200332: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n",
      "2022-10-21 11:30:08.424753: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 15:43 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.2207e-04 - factorized_top_k/top_10_categorical_accuracy: 2.4414e-04 - factorized_top_k/top_50_categorical_accuracy: 7.3242e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0011 - loss: 73817.3594 - regularization_loss: 0.0000e+00 - total_loss: 73817.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 11:31:02.226231: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n",
      "2022-10-21 11:31:02.447722: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/17 [==>...........................] - ETA: 13:35 - factorized_top_k/top_1_categorical_accuracy: 6.1035e-05 - factorized_top_k/top_5_categorical_accuracy: 5.4932e-04 - factorized_top_k/top_10_categorical_accuracy: 8.5449e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0019 - factorized_top_k/top_100_categorical_accuracy: 0.0022 - loss: 73817.2148 - regularization_loss: 0.0000e+00 - total_loss: 73817.2148    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 11:31:56.540478: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 800s 46s/step - factorized_top_k/top_1_categorical_accuracy: 1.6286e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0024 - factorized_top_k/top_10_categorical_accuracy: 0.0047 - factorized_top_k/top_50_categorical_accuracy: 0.0200 - factorized_top_k/top_100_categorical_accuracy: 0.0281 - loss: 69218.1267 - regularization_loss: 0.0000e+00 - total_loss: 69218.1267\n",
      "Epoch 2/3\n",
      "17/17 [==============================] - 667s 39s/step - factorized_top_k/top_1_categorical_accuracy: 9.7718e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0101 - factorized_top_k/top_10_categorical_accuracy: 0.0209 - factorized_top_k/top_50_categorical_accuracy: 0.0958 - factorized_top_k/top_100_categorical_accuracy: 0.1340 - loss: 66956.1649 - regularization_loss: 0.0000e+00 - total_loss: 66956.1649\n",
      "Epoch 3/3\n",
      "17/17 [==============================] - 703s 41s/step - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0282 - factorized_top_k/top_10_categorical_accuracy: 0.0563 - factorized_top_k/top_50_categorical_accuracy: 0.2084 - factorized_top_k/top_100_categorical_accuracy: 0.2565 - loss: 58953.7589 - regularization_loss: 0.0000e+00 - total_loss: 58953.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f9829e5b640>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrackRetrievalModel(user_model, track_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "#both train and test splits only include the 'ratings' dataset\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not especially high chance of the positive examples being in the top 100. Model is not learning the data well enough. Maybe not surprising given the limited features have been fed into it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 174s 19s/step - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0128 - factorized_top_k/top_10_categorical_accuracy: 0.0298 - factorized_top_k/top_50_categorical_accuracy: 0.1584 - factorized_top_k/top_100_categorical_accuracy: 0.2043 - loss: 25110.9565 - regularization_loss: 0.0000e+00 - total_loss: 25110.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'factorized_top_k/top_1_categorical_accuracy': 0.0014806040562689304,\n 'factorized_top_k/top_5_categorical_accuracy': 0.012792419642210007,\n 'factorized_top_k/top_10_categorical_accuracy': 0.02984897792339325,\n 'factorized_top_k/top_50_categorical_accuracy': 0.1583654135465622,\n 'factorized_top_k/top_100_categorical_accuracy': 0.20432336628437042,\n 'loss': 5892.62158203125,\n 'regularization_loss': 0,\n 'total_loss': 5892.62158203125}"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quite similar results for the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making predictions (for retrieval of queries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 16:51:17.928073: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 100044\n",
      "2022-10-21 16:51:18.302408: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 374.261723ms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function ScannState.recreate_handle at 0x7f982049f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model, k=100)\n",
    "scann_index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((tracks.batch(100), tracks.batch(100).map(model.track_model)))\n",
    ")\n",
    "\n",
    "result = scann_index(np.array(['kv718oiku8q612q0zi4iaovzb']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/spotify_retrieval_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/spotify_retrieval_v1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    scann_index,\n",
    "    './models/spotify_retrieval_v1',\n",
    "    options=tf.saved_model.SaveOptions(namespace_whitelist=['Scann']),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ignore!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "recs = []\n",
    "temp = result[1].numpy().reshape(-1)\n",
    "for rec in temp:\n",
    "    recs.append(rec.decode('UTF-8').split('/'))\n",
    "\n",
    "recs = pd.DataFrame(recs, columns=['artist', 'track'])\n",
    "actual_playlist = df[df['owner'] == 'kv718oiku8q612q0zi4iaovzb'][['artist','track']]\n",
    "new_recs = pd.concat([recs, actual_playlist]).drop_duplicates(keep=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "#new_recs.merge(df[['artist','track','track_id']], how='inner').drop_duplicates(subset=['artist', 'track'],keep='first')['track_id'].to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ranking Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_songs_ranking = user_data.map(lambda x: {\n",
    "    'user': x['owner'],\n",
    "    'artist&track': x['artist&track'],\n",
    "    'popularity': x['popularity'],\n",
    "})\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "shuffled_ranking = user_songs_ranking.shuffle(buffersize, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train_ranking = shuffled.take(int(0.8*buffersize))\n",
    "test_ranking = shuffled.skip(int(0.8*buffersize)).take(int(0.2*buffersize))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, usr_model, film_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = usr_model\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.track_embeddings = track_model\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "            # Learn multiple dense layers.\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            # Make rating predictions in the final layer.\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, track_name = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        track_embedding = self.track_embeddings(track_name)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, track_embedding], axis=1))\n",
    "\n",
    "\n",
    "class TrackRankingModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, usr_model, track_model):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel(usr_model, track_model)\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features) -> tf.Tensor:\n",
    "        return self.ranking_model(\n",
    "            (features[\"user_id\"], features[\"track\"]))\n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        labels = features.pop(\"user_rating\")\n",
    "\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ranking_model = TrackRankingModel(user_model, track_model)\n",
    "ranking_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "cached_train_ranking = train_ranking.shuffle(buffersize).batch(8192).cache()\n",
    "cached_test_ranking = test_ranking.batch(4096).cache()\n",
    "\n",
    "ranking_model.fit(cached_train_ranking, epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

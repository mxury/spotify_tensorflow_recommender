{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 10:35:12.702640: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 10:35:12.952653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-24 10:35:12.952693: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-24 10:35:13.006088: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-24 10:35:14.380473: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-24 10:35:14.380596: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-24 10:35:14.380609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist           object\n",
      "track_id         object\n",
      "track            object\n",
      "owner            object\n",
      "popularity      float64\n",
      "artist&track     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "              artist                track_id           track  \\\n0         Romanthony  1iwZVgKv3FKc0dqhnSG9uW  Get It 2 Getta   \n1  Glenn Underground  2JFeAyJLMPPsBkklQEet6t         H-Dance   \n2          DJ BORING  3ilkEyg6OCtd9qCnOJkPzU          Winona   \n3          DJ BORING  3ilkEyg6OCtd9qCnOJkPzU          Winona   \n4          DJ BORING  3ilkEyg6OCtd9qCnOJkPzU          Winona   \n\n                       owner  popularity               artist&track  \n0  kv718oiku8q612q0zi4iaovzb        22.0  Romanthony/Get It 2 Getta  \n1  kv718oiku8q612q0zi4iaovzb         7.0  Glenn Underground/H-Dance  \n2  kv718oiku8q612q0zi4iaovzb        52.0           DJ BORING/Winona  \n3  botetauw3lk6anvygizm8wolf        52.0           DJ BORING/Winona  \n4              thebootlegboy        52.0           DJ BORING/Winona  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>track_id</th>\n      <th>track</th>\n      <th>owner</th>\n      <th>popularity</th>\n      <th>artist&amp;track</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Romanthony</td>\n      <td>1iwZVgKv3FKc0dqhnSG9uW</td>\n      <td>Get It 2 Getta</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>22.0</td>\n      <td>Romanthony/Get It 2 Getta</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Glenn Underground</td>\n      <td>2JFeAyJLMPPsBkklQEet6t</td>\n      <td>H-Dance</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>7.0</td>\n      <td>Glenn Underground/H-Dance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DJ BORING</td>\n      <td>3ilkEyg6OCtd9qCnOJkPzU</td>\n      <td>Winona</td>\n      <td>kv718oiku8q612q0zi4iaovzb</td>\n      <td>52.0</td>\n      <td>DJ BORING/Winona</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DJ BORING</td>\n      <td>3ilkEyg6OCtd9qCnOJkPzU</td>\n      <td>Winona</td>\n      <td>botetauw3lk6anvygizm8wolf</td>\n      <td>52.0</td>\n      <td>DJ BORING/Winona</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DJ BORING</td>\n      <td>3ilkEyg6OCtd9qCnOJkPzU</td>\n      <td>Winona</td>\n      <td>thebootlegboy</td>\n      <td>52.0</td>\n      <td>DJ BORING/Winona</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database is small enough to be read into memory hence we will use pandas and then cast it into a tf.data object\n",
    "df = pd.read_csv('./data/database_EDA.csv')\n",
    "df = df.dropna()\n",
    "all_tracks = df['artist&track'].unique()\n",
    "pprint(df.dtypes)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Romanthony/Get It 2 Getta', 'Glenn Underground/H-Dance',\n       'DJ BORING/Winona', ..., 'Joni Mitchell/Edith and the Kingpin',\n       \"Joni Mitchell/Don't Interrupt the Sorrow\",\n       'Joni Mitchell/The Hissing of Summer Lawns'], dtype=object)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tracks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "user_data = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "tracks = tf.data.Dataset.from_tensor_slices({'artist&track' : all_tracks})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist': b'Romanthony', 'track_id': b'1iwZVgKv3FKc0dqhnSG9uW', 'track': b'Get It 2 Getta', 'owner': b'kv718oiku8q612q0zi4iaovzb', 'popularity': 22.0, 'artist&track': b'Romanthony/Get It 2 Getta'}\n"
     ]
    }
   ],
   "source": [
    "for row in user_data.take(1).as_numpy_iterator():\n",
    "    print(row)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist&track': b'Romanthony/Get It 2 Getta'}\n"
     ]
    }
   ],
   "source": [
    "for row in tracks.take(1).as_numpy_iterator():\n",
    "    print(row)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "user_songs = user_data.map(lambda x: {\n",
    "    'user': x['owner'],\n",
    "    'artist&track': x['artist&track'],\n",
    "})\n",
    "\n",
    "tracks = tracks.map(lambda x: x['artist&track'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([b' Sentinel/Toulepleu', b'!!!/Fine Fine Fine', b'!!!/Myth Takes',\n       b'!!!/NRGQ',\n       b'#1 Movie Favorites/The Winner Is (From Little Miss Sunshine)',\n       b'#TocoParaVos/Se Pic\\xc3\\xb3', b'$MOKE OG/$MOKE OG',\n       b'$NOT/\"Life\"', b'$NOT/5AM', b'$NOT/BENZO'], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "buffersize = df.shape[0]\n",
    "shuffled = user_songs.shuffle(buffersize, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(0.8*buffersize))\n",
    "test = shuffled.skip(int(0.8*buffersize)).take(int(0.2*buffersize))\n",
    "\n",
    "track_names = tracks.batch(1_000)\n",
    "user_ids = user_songs.batch(1_000_000).map(lambda x: x[\"user\"])\n",
    "\n",
    "unique_track_names = np.unique(np.concatenate(list(track_names)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_track_names[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieval model\n",
    "\n",
    "Following the tutorial from [Tensorflow](https://www.tensorflow.org/recommenders/examples/basic_retrieval)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query and candidate towers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "# stringlook up encodes the user id's as continuous integers and then uses an embedding\n",
    "# similar process for the\n",
    "user_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids,\n",
    "            mask_token=None,\n",
    "        ),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
    "    ]\n",
    ")\n",
    "\n",
    "track_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_track_names,\n",
    "            mask_token=None,\n",
    "        ),\n",
    "        tf.keras.layers.Embedding(len(unique_track_names) + 1, embedding_dimension)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=tracks.batch(128).map(track_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Full retrieval model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class TrackRetrievalModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, usr_model, track_model):\n",
    "        super().__init__()\n",
    "        self.track_model: tf.keras.Model = track_model\n",
    "        self.user_model: tf.keras.Model = usr_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user\"])\n",
    "        # And pick out the track features and pass them into the track model,\n",
    "        # getting embeddings back.\n",
    "        positive_track_embeddings = self.track_model(features[\"artist&track\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_track_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting and evaluating the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 10:37:13.531958: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n",
      "2022-10-24 10:37:13.726722: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 11:21 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 6.1035e-04 - factorized_top_k/top_100_categorical_accuracy: 9.7656e-04 - loss: 73817.8750 - regularization_loss: 0.0000e+00 - total_loss: 73817.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 10:37:55.061680: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n",
      "2022-10-24 10:37:55.199816: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/16 [==>...........................] - ETA: 10:00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 3.6621e-04 - factorized_top_k/top_10_categorical_accuracy: 3.6621e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0012 - factorized_top_k/top_100_categorical_accuracy: 0.0018 - loss: 73817.8789 - regularization_loss: 0.0000e+00 - total_loss: 73817.8789        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 10:38:37.975515: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 268435456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 628s 39s/step - factorized_top_k/top_1_categorical_accuracy: 2.3199e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0024 - factorized_top_k/top_50_categorical_accuracy: 0.0106 - factorized_top_k/top_100_categorical_accuracy: 0.0150 - loss: 71750.6737 - regularization_loss: 0.0000e+00 - total_loss: 71750.6737\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 614s 38s/step - factorized_top_k/top_1_categorical_accuracy: 3.8664e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0086 - factorized_top_k/top_10_categorical_accuracy: 0.0195 - factorized_top_k/top_50_categorical_accuracy: 0.0875 - factorized_top_k/top_100_categorical_accuracy: 0.1265 - loss: 70313.9324 - regularization_loss: 0.0000e+00 - total_loss: 70313.9324\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 636s 40s/step - factorized_top_k/top_1_categorical_accuracy: 0.0022 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0477 - factorized_top_k/top_50_categorical_accuracy: 0.1675 - factorized_top_k/top_100_categorical_accuracy: 0.2183 - loss: 63174.9858 - regularization_loss: 0.0000e+00 - total_loss: 63174.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fec05119f70>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrackRetrievalModel(user_model, track_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "#both train and test splits only include the 'ratings' dataset\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not especially high chance of the positive examples being in the top 100. Model is not learning the data well enough. Maybe not surprising given the limited features have been fed into it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 166s 21s/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0095 - factorized_top_k/top_10_categorical_accuracy: 0.0228 - factorized_top_k/top_50_categorical_accuracy: 0.1196 - factorized_top_k/top_100_categorical_accuracy: 0.1605 - loss: 30131.6999 - regularization_loss: 0.0000e+00 - total_loss: 30131.6999\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'factorized_top_k/top_1_categorical_accuracy': 0.0011135513195767999,\n 'factorized_top_k/top_5_categorical_accuracy': 0.009465185925364494,\n 'factorized_top_k/top_10_categorical_accuracy': 0.0227968692779541,\n 'factorized_top_k/top_50_categorical_accuracy': 0.11961396783590317,\n 'factorized_top_k/top_100_categorical_accuracy': 0.1605369746685028,\n 'loss': 27237.46875,\n 'regularization_loss': 0,\n 'total_loss': 27237.46875}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quite similar results for the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making predictions (for retrieval of queries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 11:31:48.871540: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 100044\n",
      "2022-10-24 11:31:49.161391: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 289.253589ms.\n"
     ]
    }
   ],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model, k=100)\n",
    "scann_index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((tracks.batch(100), tracks.batch(100).map(model.track_model)))\n",
    ")\n",
    "\n",
    "result = scann_index(np.array(['kv718oiku8q612q0zi4iaovzb']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n array([[1.699753 , 1.653338 , 1.606923 , 1.5787424, 1.575427 , 1.565481 ,\n         1.5555348, 1.5472465, 1.5373003, 1.5306697, 1.5306697, 1.5273542,\n         1.5256966, 1.524039 , 1.5223813, 1.5223813, 1.5190659, 1.5174083,\n         1.5008314, 1.4991738, 1.4908854, 1.4792817, 1.4709932, 1.4610472,\n         1.4511011, 1.4477856, 1.441155 , 1.4394972, 1.4361819, 1.4278935,\n         1.4245782, 1.4245782, 1.4179474, 1.409659 , 1.4048991, 1.404686 ,\n         1.4013706, 1.3997129, 1.3997129, 1.3997129, 1.3947399, 1.3947399,\n         1.3947399, 1.3881092, 1.3864515, 1.3814785, 1.3814785, 1.3781631,\n         1.3781631, 1.3715324, 1.3698747, 1.363244 , 1.3615863, 1.3615863,\n         1.3615863, 1.3599286, 1.3551688, 1.353298 , 1.353298 , 1.3483249,\n         1.3483249, 1.3450096, 1.3416941, 1.3416941, 1.3400365, 1.3367212,\n         1.3334057, 1.3251173, 1.3251173, 1.3251173, 1.3234596, 1.3234596,\n         1.3201443, 1.316829 , 1.3151712, 1.3135136, 1.3118559, 1.3118559,\n         1.3101983, 1.3085406, 1.307096 , 1.3052251, 1.3019098, 1.3019098,\n         1.2952791, 1.2952791, 1.2936214, 1.2919638, 1.2903061, 1.285333 ,\n         1.285333 , 1.285333 , 1.285333 , 1.2770447, 1.2737293, 1.2737293,\n         1.2737293, 1.2637832, 1.2623386, 1.2604678]], dtype=float32)>,\n <tf.Tensor: shape=(1, 100), dtype=string, numpy=\n array([[b\"\\xeb\\xb0\\x95\\xed\\x98\\x9c\\xec\\xa7\\x84 Park Hye Jin/I DON'T CARE\",\n         b'No_4mat/1992', b'Tom Jarmey/Beach Jazz',\n         b\"dj poolboi/pretend we're okay\", b'DJ BORING/Winona',\n         b'dj poolboi/Forever Yours', b'Subjoi/The Way I Feel',\n         b'Ra\\xc3\\xa4r/Sometimes I Hear Sirens',\n         b\"dj poolboi/don't be so hard on yourself\",\n         b'Dj Kush Boogie/Orchid', b'Tell/In The Sky',\n         b'Subjoi/Flashing Lights', b'dj poolboi/Leave Here',\n         b'Pachanga Boys/Time', b'dj poolboi/we can be happy',\n         b'Yaeji/raingurl',\n         b\"DJ Planet Express/More Than You'd Ever Wanna Know\",\n         b'DJ BORING/Different Dates', b'COMPUTER DATA/Alles',\n         b'COMPUTER DATA/Schlafen', b'dj poolboi/I Had It All',\n         b\"n\\xc3\\xb8rus/I'll wait for u tonight\",\n         b\"dj poolboi/l'amour perdu\", b'Peggy Gou/Starry Night - Edit',\n         b'1-800 GIRLS/U, Me and Madonna',\n         b'dj poolboi/like we were the last two people on earth',\n         b'Jesper Ryom/Pacer',\n         b'Purple Velvet/Back On The Boulevard - Original Mix',\n         b'DJ BORING/For Tahn', b'Obsk\\xc3\\xbcr/Bayside - Radio Edit',\n         b'n\\xc3\\xb8rus/make a move', b'Weast/Cocola',\n         b'Quasar/I Never Thought', b'Bellaire/Pigalle',\n         b\"Summer Walker/I'll Kill You (feat. Jhen\\xc3\\xa9 Aiko)\",\n         b'Mall Grab/Bust', b'Harrison BDP/Decompression',\n         b'COMPUTER DATA/Seele', b'Tell/Cool Bananas',\n         b'Demuja/Turn Me On', b'COMPUTER DATA/Alright',\n         b'Sweely/All the Reasons', b'Tlim Shug/Funeral Errday',\n         b'jamesjamesjames/homesoon.',\n         b'808 State/In Yer Face - Bicep Remix',\n         b\"Harrison BDP/It's Foggy Outside\", b'Adryiano/On My Side',\n         b'Demuja/Loose Legs', b'Coeo/Like It Is - Mixed',\n         b'Mood J/NY Vibration', b'Demuja/Move',\n         b'Theo Parrish/Heal Yourself And Move',\n         b'Matthieu Faubourg/Please, Stay', b'Demuja/Getting Dark',\n         b'upper class/Six Million', b'Horsemen/Voltaire',\n         b'SZA/The Weekend', b'Mark Blair/Biggie Was A Jazz Fan (Dub)',\n         b\"dj poolboi/it's alright now\", b'Harrison BDP/Parallax',\n         b'Bruce Trail/Bridgework', b'Kronol/KRONOLOGIA',\n         b'COMPUTER DATA/U', b'Li\\xc3\\xaam/Rave (Sylt TV)',\n         b'COMPUTER DATA/Healing', b'Mall Grab/Catching Feelings',\n         b'DJ \\xc3\\x86DIDIAS/flexin on my x',\n         b'Demuja/Do You Want My Love', b'upper class/3AM Gang Shit',\n         b'V.I.C.A.R.I./Pasci\\xc3\\xa0',\n         b'Flight Facilities/Crave You - Hush Hush Bootleg',\n         b'Robby & Stupid Flash/Stargazer',\n         b'Pacific Coliseum/Ocean City', b'Miagma/You',\n         b'Tour-Maubourg/Manhattan to Brooklyn',\n         b'HNNY/Most Really Pretty Girls Have Pretty Ugly Feet',\n         b'No_4mat/Runaway Girl', b'COMPUTER DATA/Leer',\n         b\"Ross from Friends/Talk to Me You'll Understand\",\n         b\"Subjoi/Love Shy - Subjoi's Tuff Jam Rework\",\n         b'SZA/Doves In The Wind (feat. Kendrick Lamar)',\n         b'so. mind/Good Conditions', b\"Hush Hush/Thinkin' Bout You\",\n         b'Yaeji/One More', b'The xx/On Hold - Jamie xx Remix',\n         b'Tell/I Lost 200\\xe2\\x82\\xac in a Club',\n         b'COMPUTER DATA/Traumfolge', b'Fresh & Low/New Life',\n         b\"Yaeji/drink i'm sippin on\", b'Yaeji/Guap',\n         b'Folamour/Ya Just Need 2 Believe in Yaself',\n         b'DJ Planet Express/Take Me',\n         b\"Boris Dlugosch/Keep Pushin' - Purple Disco Maschine Vox Mix\",\n         b'mouse on the keys/Stars Down (feat. Dominique Fils-Aime) [So Inagawa Remix]',\n         b'Korn\\xc3\\xa9l Kov\\xc3\\xa1cs/Szikra',\n         b'Enrico Mantini/What U Want - Chris Stussy & Djoko Remix',\n         b'Trudge/Give', b'Tlim Shug/Surf Dude', b'SZA/Drew Barrymore',\n         b'Yazmine/Spell (Stullett Remix)']], dtype=object)>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/spotify_retrieval_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/spotify_retrieval_v1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    scann_index,\n",
    "    './models/spotify_retrieval_v1',\n",
    "    options=tf.saved_model.SaveOptions(namespace_whitelist=['Scann']),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ignore!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "recs = []\n",
    "temp = result[1].numpy().reshape(-1)\n",
    "for rec in temp:\n",
    "    recs.append(rec.decode('UTF-8').split('/'))\n",
    "\n",
    "recs = pd.DataFrame(recs, columns=['artist', 'track'])\n",
    "actual_playlist = df[df['owner'] == 'kv718oiku8q612q0zi4iaovzb'][['artist','track']]\n",
    "new_recs = pd.concat([recs, actual_playlist]).drop_duplicates(keep=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "#new_recs.merge(df[['artist','track','track_id']], how='inner').drop_duplicates(subset=['artist', 'track'],keep='first')['track_id'].to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ranking Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "user_songs_ranking = user_data.map(lambda x: {\n",
    "    'user': x['owner'],\n",
    "    'artist&track': x['artist&track'],\n",
    "    'popularity': x['popularity'],\n",
    "})\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "shuffled_ranking = user_songs_ranking.shuffle(buffersize, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train_ranking = shuffled_ranking.take(int(0.8*buffersize))\n",
    "test_ranking = shuffled_ranking.skip(int(0.8*buffersize)).take(int(0.2*buffersize))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, usr_model, film_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = usr_model\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.track_embeddings = track_model\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "            # Learn multiple dense layers.\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            # Make rating predictions in the final layer.\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, track_name = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        track_embedding = self.track_embeddings(track_name)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, track_embedding], axis=1))\n",
    "\n",
    "\n",
    "class TrackRankingModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, usr_model, track_model):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel(usr_model, track_model)\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features) -> tf.Tensor:\n",
    "        return self.ranking_model(\n",
    "            (features[\"user\"], features[\"artist&track\"]))\n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        labels = features.pop(\"popularity\")\n",
    "\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 50ms/step - root_mean_squared_error: 34.1129 - loss: 1095.8629 - regularization_loss: 0.0000e+00 - total_loss: 1095.8629\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 14.3533 - loss: 200.3647 - regularization_loss: 0.0000e+00 - total_loss: 200.3647\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 35ms/step - root_mean_squared_error: 11.5339 - loss: 130.1156 - regularization_loss: 0.0000e+00 - total_loss: 130.1156\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 10.1547 - loss: 101.3454 - regularization_loss: 0.0000e+00 - total_loss: 101.3454\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 32ms/step - root_mean_squared_error: 9.3476 - loss: 86.2340 - regularization_loss: 0.0000e+00 - total_loss: 86.2340\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7febb617f5e0>"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model = TrackRankingModel(user_model, track_model)\n",
    "ranking_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "cached_train_ranking = train_ranking.shuffle(buffersize).batch(8192).cache()\n",
    "cached_test_ranking = test_ranking.batch(4096).cache()\n",
    "\n",
    "ranking_model.fit(cached_train_ranking, epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 25ms/step - root_mean_squared_error: 16.9162 - loss: 286.2498 - regularization_loss: 0.0000e+00 - total_loss: 286.2498\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'root_mean_squared_error': 16.916194915771484,\n 'loss': 286.89654541015625,\n 'regularization_loss': 0,\n 'total_loss': 286.89654541015625}"
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model.evaluate(cached_test_ranking, return_dict=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combining the two models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings: \n",
      "track: b'Peggy Gou/Starry Night - Edit', score: [[51.789352]]\n",
      "track: b'Tell/Cool Bananas', score: [[48.4002]]\n",
      "track: b'V.I.C.A.R.I./Pasci\\xc3\\xa0 - Dub', score: [[46.881058]]\n",
      "track: b'COMPUTER DATA/Healing', score: [[46.52957]]\n",
      "track: b'No_4mat/1992', score: [[46.102833]]\n",
      "track: b'Tom Jarmey/Beach Jazz', score: [[43.92224]]\n",
      "track: b'Tell/I Lost 200\\xe2\\x82\\xac in a Club', score: [[42.54987]]\n",
      "track: b\"\\xeb\\xb0\\x95\\xed\\x98\\x9c\\xec\\xa7\\x84 Park Hye Jin/I DON'T CARE\", score: [[41.658184]]\n",
      "track: b'Korn\\xc3\\xa9l Kov\\xc3\\xa1cs/Szikra', score: [[41.56623]]\n",
      "track: b'Adryiano/On My Side', score: [[41.220066]]\n",
      "track: b'Pachanga Boys/Time', score: [[39.990913]]\n",
      "track: b'V.I.C.A.R.I./Pasci\\xc3\\xa0', score: [[39.51571]]\n",
      "track: b'Coeo/Like It Is - Mixed', score: [[38.96499]]\n",
      "track: b'Demuja/Do You Want My Love', score: [[38.038883]]\n",
      "track: b'Leo Pol/This must be illegal', score: [[37.847115]]\n",
      "track: b'Pacific Coliseum/Ocean City', score: [[37.49597]]\n",
      "track: b\"dj poolboi/don't be so hard on yourself\", score: [[37.396774]]\n",
      "track: b'Quasar/I Never Thought', score: [[37.014515]]\n",
      "track: b'COMPUTER DATA/Seele', score: [[36.97785]]\n",
      "track: b'1-800 GIRLS/U, Me and Madonna', score: [[36.323193]]\n",
      "track: b'Yazmine/Spell (Stullett Remix)', score: [[35.518406]]\n",
      "track: b\"Subjoi/Love Shy - Subjoi's Tuff Jam Rework\", score: [[35.277885]]\n",
      "track: b'Harrison BDP/Decompression', score: [[34.857014]]\n",
      "track: b'Jesper Ryom/Pacer', score: [[34.707573]]\n",
      "track: b'Project Pablo/Dustman', score: [[34.660976]]\n",
      "track: b'Weast/Cocola', score: [[34.33613]]\n",
      "track: b'n\\xc3\\xb8rus/make a move', score: [[33.839672]]\n",
      "track: b'808 State/In Yer Face - Bicep Remix', score: [[33.44267]]\n",
      "track: b'Purple Velvet/Back On The Boulevard - Original Mix', score: [[33.406155]]\n",
      "track: b'dj poolboi/like we were the last two people on earth', score: [[33.228966]]\n",
      "track: b'Earth Boys/Myrtle Music - Original Mix', score: [[32.70571]]\n",
      "track: b\"Hush Hush/Thinkin' Bout You\", score: [[32.399487]]\n",
      "track: b'upper class/Six Million', score: [[31.829664]]\n",
      "track: b'Demuja/Loose Legs', score: [[31.748959]]\n",
      "track: b'COMPUTER DATA/Traumfolge', score: [[31.401583]]\n",
      "track: b'Horsemen/Voltaire', score: [[30.67621]]\n",
      "track: b'Kronol/KRONOLOGIA', score: [[30.491772]]\n",
      "track: b'John Tejada/Farther And Fainter', score: [[30.232046]]\n",
      "track: b'Mood J/NY Vibration', score: [[29.88562]]\n",
      "track: b'COMPUTER DATA/Fog', score: [[29.66119]]\n",
      "track: b'COMPUTER DATA/Schlafen', score: [[28.552803]]\n",
      "track: b'jamesjamesjames/homesoon.', score: [[27.855343]]\n",
      "track: b\"n\\xc3\\xb8rus/I'll wait for u tonight\", score: [[27.362408]]\n",
      "track: b'DOS/Need U', score: [[27.09131]]\n",
      "track: b'Theo Parrish/Heal Yourself And Move', score: [[26.897154]]\n",
      "track: b'DJ BORING/For Tahn', score: [[26.74013]]\n",
      "track: b'dj poolboi/we can be happy', score: [[26.731504]]\n",
      "track: b'COMPUTER DATA/Alright', score: [[26.724194]]\n",
      "track: b'COMPUTER DATA/U', score: [[26.443739]]\n",
      "track: b'COMPUTER DATA/Alles', score: [[26.441383]]\n",
      "track: b'R.M/Chikyu-u 002', score: [[25.984446]]\n",
      "track: b'DJ BORING/Winona', score: [[25.252254]]\n",
      "track: b'No_4mat/Runaway Girl', score: [[25.165874]]\n",
      "track: b'Fresh & Low/New Life', score: [[25.006517]]\n",
      "track: b'Demuja/Turn Me On', score: [[24.945139]]\n",
      "track: b'Chaos In The CBD/Luxury Motivation', score: [[24.58966]]\n",
      "track: b'Demuja/Getting Dark', score: [[24.255842]]\n",
      "track: b\"dj poolboi/pretend we're okay\", score: [[23.910341]]\n",
      "track: b'upper class/3AM Gang Shit', score: [[23.821321]]\n",
      "track: b'Bellaire/Pigalle', score: [[23.817795]]\n",
      "track: b'DJ Planet Express/Take Me', score: [[23.150307]]\n",
      "track: b'DJ Seinfeld/U', score: [[22.956903]]\n",
      "track: b'Flight Facilities/Crave You - Hush Hush Bootleg', score: [[22.447695]]\n",
      "track: b'COMPUTER DATA/Leer', score: [[21.400688]]\n",
      "track: b'dj poolboi/I Had It All', score: [[21.263226]]\n",
      "track: b'Demuja/I Want You', score: [[21.262993]]\n",
      "track: b'dj poolboi/Forever Yours', score: [[21.223436]]\n",
      "track: b'Folamour/Ya Just Need 2 Believe in Yaself', score: [[20.720688]]\n",
      "track: b'dj poolboi/Leave Here', score: [[20.47728]]\n",
      "track: b\"Ross from Friends/Talk to Me You'll Understand\", score: [[19.963276]]\n",
      "track: b'Bruce Trail/Bridgework', score: [[19.877094]]\n",
      "track: b'so. mind/Good Conditions', score: [[19.513823]]\n",
      "track: b'Tlim Shug/Funeral Errday', score: [[18.865402]]\n",
      "track: b\"dj poolboi/l'amour perdu\", score: [[17.721075]]\n",
      "track: b'Dj Kush Boogie/Orchid', score: [[16.591896]]\n",
      "track: b'Demuja/Move', score: [[16.56519]]\n",
      "track: b'Trudge/Give', score: [[16.414131]]\n",
      "track: b\"dj poolboi/it's alright now\", score: [[15.992912]]\n",
      "track: b'Ra\\xc3\\xa4r/Sometimes I Hear Sirens', score: [[13.388333]]\n",
      "track: b'Tell/In The Sky', score: [[10.298797]]\n",
      "track: b'Project Pablo/Sky Lounge', score: [[8.883184]]\n",
      "track: b\"DJ Planet Express/More Than You'd Ever Wanna Know\", score: [[8.343666]]\n",
      "track: b'Mall Grab/Bust', score: [[7.9464912]]\n",
      "track: b\"DJ BORING/Don't Love Me\", score: [[7.8455095]]\n",
      "track: b'Subjoi/Flashing Lights', score: [[6.0830154]]\n",
      "track: b'DJ BORING/Different Dates', score: [[5.048629]]\n",
      "track: b'Yaeji/Guap', score: [[4.143345]]\n",
      "track: b'Clarence G/Data Transfer', score: [[3.9806435]]\n",
      "track: b'L.A.M./Irradiated', score: [[3.9309826]]\n",
      "track: b'Subjoi/The Way I Feel', score: [[3.0326602]]\n",
      "track: b'DJ \\xc3\\x86DIDIAS/flexin on my x', score: [[2.276423]]\n",
      "track: b'L.A.M./Nuclear Facelift', score: [[2.2502532]]\n",
      "track: b'Harrison BDP/Parallax', score: [[0.5038686]]\n",
      "track: b'Yaeji/One More', score: [[0.1352195]]\n",
      "track: b'Yaeji/raingurl', score: [[0.11556126]]\n",
      "track: b'Chaos In The CBD/78 to Stanley Bay', score: [[0.11556126]]\n",
      "track: b\"Harrison BDP/It's Foggy Outside\", score: [[0.11556126]]\n",
      "track: b'Mall Grab/Catching Feelings', score: [[0.11556126]]\n",
      "track: b\"Yaeji/drink i'm sippin on\", score: [[0.11556126]]\n",
      "track: b'Subjoi/VIP', score: [[0.11556126]]\n"
     ]
    }
   ],
   "source": [
    "user_id = np.array(['kv718oiku8q612q0zi4iaovzb'])\n",
    "\n",
    "#use the retrieval model to produce the top 100 films for user_id\n",
    "top100tracks = scann_index(user_id)[1].numpy()\n",
    "top100tracks = top100tracks.reshape(100)\n",
    "\n",
    "predicted_tracks = {}\n",
    "for track in top100tracks:\n",
    "    predicted_tracks[track] = ranking_model({\n",
    "        'user': user_id,\n",
    "        'artist&track': np.array([track])\n",
    "    })\n",
    "\n",
    "\n",
    "print('Ratings: ')\n",
    "for track, score in sorted(predicted_tracks.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'track: {track}, score: {score}')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
